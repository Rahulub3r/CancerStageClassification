{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Genric Libraries\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the images to make them ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a fixed width and height of the image as that is required for training\n",
    "width = 64\n",
    "height = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping the images\n",
    "\n",
    "#Give the three directories for stage1, stage3 and normal cells. Choose any one sample\n",
    "dirc1=\"Data/cancer cell data/b_all_1_stage3/sample1/\"\n",
    "dirc2=\"Data/cancer cell data/rs411_stage1/sample2/\"\n",
    "dirc3=\"Data/normal/b_cells_control/qpi/sample6/\"\n",
    "dirs1=[dirc1+s for s in os.listdir(dirc1)]\n",
    "dirs2=[dirc2+s for s in os.listdir(dirc2)]\n",
    "dirs3=[dirc3+s for s in os.listdir(dirc3)]\n",
    "dirs=(dirs1, dirs2, dirs3)\n",
    "\n",
    "stage3=[]\n",
    "stage1=[]\n",
    "normal=[]\n",
    "for dirs_list in sorted(dirs):\n",
    "    \n",
    "    for directory in dirs_list:\n",
    "        #reading the image \n",
    "        idx=0\n",
    "        image = cv2.imread(directory)\n",
    "        image = image[85:540, 100:710]\n",
    "        edged = cv2.Canny(image, 10, 250)\n",
    "\n",
    "        #applying closing function \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "        closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        #finding_contours \n",
    "        (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for c in cnts:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if w>50 and h>50:\n",
    "                idx+=1\n",
    "                new_img=image[y:y+h,x:x+w]\n",
    "                if new_img.shape[0] != image.shape[0] and new_img.shape[1] != image.shape[1]:\n",
    "                    new_img=cv2.resize(new_img, (width,height))\n",
    "                    if directory.find('stage3')>0:\n",
    "                        stage3.append(new_img)\n",
    "                    elif directory.find('stage1')>0:\n",
    "                        stage1.append(new_img)\n",
    "                    else:\n",
    "                        normal.append(new_img)\n",
    "                        \n",
    "stage3=np.array(stage3)\n",
    "stage1=np.array(stage1)\n",
    "normal=np.array(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 64, 64, 3)\n",
      "(95, 64, 64, 3)\n",
      "(42, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(stage3.shape)\n",
    "print(stage1.shape)\n",
    "print(normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y datasets\n",
    "X = np.concatenate([stage3, stage1, normal], axis=0)\n",
    "y = np.concatenate([np.full(stage3.shape[0], 3),np.full(stage1.shape[0], 1),np.full(normal.shape[0], 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "trainObsCount=int(0.6*X.shape[0])\n",
    "training_idx, test_idx = indices[:trainObsCount], indices[trainObsCount:]\n",
    "X_train, X_test = X[training_idx,:], X[test_idx,:]\n",
    "y_train, y_test = y[training_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 64, 64, 3)\n",
      "(106, 64, 64, 3)\n",
      "(158,)\n",
      "(106,)\n",
      "(array([0, 1, 3]), array([36, 61, 61]))\n",
      "(array([0, 1, 3]), array([26, 41, 39]))\n"
     ]
    }
   ],
   "source": [
    "# Just check for shapes and counts\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, width, height).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, width, height).astype('float32')\n",
    "# Normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# One hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do modeling and test for accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancer_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(50, (8, 8), input_shape=(3, 64, 64), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 106 samples\n",
      "Epoch 1/30\n",
      "158/158 [==============================] - 6s 41ms/step - loss: 1.2545 - acc: 0.3924 - val_loss: 1.1209 - val_acc: 0.3679\n",
      "Epoch 2/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.9976 - acc: 0.5570 - val_loss: 0.8860 - val_acc: 0.5472\n",
      "Epoch 3/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.7329 - acc: 0.7089 - val_loss: 0.6402 - val_acc: 0.6887\n",
      "Epoch 4/30\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.7126 - acc: 0.7089 - val_loss: 0.6620 - val_acc: 0.6509\n",
      "Epoch 5/30\n",
      "158/158 [==============================] - 6s 38ms/step - loss: 0.7079 - acc: 0.6835 - val_loss: 0.6211 - val_acc: 0.7170\n",
      "Epoch 6/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.5871 - acc: 0.7152 - val_loss: 0.5588 - val_acc: 0.6792\n",
      "Epoch 7/30\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.5826 - acc: 0.7405 - val_loss: 0.5431 - val_acc: 0.7547\n",
      "Epoch 8/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.5208 - acc: 0.7785 - val_loss: 0.4661 - val_acc: 0.7925\n",
      "Epoch 9/30\n",
      "158/158 [==============================] - 6s 38ms/step - loss: 0.4448 - acc: 0.8228 - val_loss: 0.5500 - val_acc: 0.7830\n",
      "Epoch 10/30\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.4748 - acc: 0.7848 - val_loss: 0.4954 - val_acc: 0.7736\n",
      "Epoch 11/30\n",
      "158/158 [==============================] - 7s 46ms/step - loss: 0.4447 - acc: 0.8038 - val_loss: 0.4712 - val_acc: 0.8208\n",
      "Epoch 12/30\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.4047 - acc: 0.8291 - val_loss: 0.6232 - val_acc: 0.7358\n",
      "Epoch 13/30\n",
      "158/158 [==============================] - 8s 50ms/step - loss: 0.4317 - acc: 0.8101 - val_loss: 0.4947 - val_acc: 0.8113\n",
      "Epoch 14/30\n",
      "158/158 [==============================] - 7s 47ms/step - loss: 0.3355 - acc: 0.8861 - val_loss: 0.4256 - val_acc: 0.8491\n",
      "Epoch 15/30\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.3250 - acc: 0.8734 - val_loss: 0.4421 - val_acc: 0.8396\n",
      "Epoch 16/30\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.2778 - acc: 0.8924 - val_loss: 0.4701 - val_acc: 0.8302\n",
      "Epoch 17/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.2988 - acc: 0.8924 - val_loss: 0.6516 - val_acc: 0.7925\n",
      "Epoch 18/30\n",
      "158/158 [==============================] - 7s 42ms/step - loss: 0.2940 - acc: 0.8924 - val_loss: 0.4646 - val_acc: 0.8113\n",
      "Epoch 19/30\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.2268 - acc: 0.9241 - val_loss: 0.4464 - val_acc: 0.8113\n",
      "Epoch 20/30\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.2320 - acc: 0.9177 - val_loss: 0.5732 - val_acc: 0.7736\n",
      "Epoch 21/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.3444 - acc: 0.8544 - val_loss: 0.5243 - val_acc: 0.7547\n",
      "Epoch 22/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.2665 - acc: 0.8734 - val_loss: 0.5064 - val_acc: 0.8208\n",
      "Epoch 23/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.2389 - acc: 0.9051 - val_loss: 0.5371 - val_acc: 0.7547\n",
      "Epoch 24/30\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.2051 - acc: 0.9177 - val_loss: 0.5045 - val_acc: 0.8019\n",
      "Epoch 25/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.2011 - acc: 0.9494 - val_loss: 0.5384 - val_acc: 0.8302\n",
      "Epoch 26/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.1601 - acc: 0.9494 - val_loss: 0.4761 - val_acc: 0.8113\n",
      "Epoch 27/30\n",
      "158/158 [==============================] - 6s 36ms/step - loss: 0.2033 - acc: 0.9051 - val_loss: 0.6076 - val_acc: 0.7830\n",
      "Epoch 28/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.1410 - acc: 0.9557 - val_loss: 0.4787 - val_acc: 0.8208\n",
      "Epoch 29/30\n",
      "158/158 [==============================] - 6s 39ms/step - loss: 0.1475 - acc: 0.9557 - val_loss: 0.4679 - val_acc: 0.8113\n",
      "Epoch 30/30\n",
      "158/158 [==============================] - 6s 40ms/step - loss: 0.1049 - acc: 0.9620 - val_loss: 0.5525 - val_acc: 0.7736\n",
      "CNN Misclassification Error for Test dataset: 22.64%\n"
     ]
    }
   ],
   "source": [
    "model = cancer_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=20)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Misclassification Error for Test dataset: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5525172816694908, 0.7735849067849933]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores # the names of the values are as displayed by the output of the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
